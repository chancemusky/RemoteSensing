{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114f31d3",
   "metadata": {},
   "source": [
    "This is a notebook following the \"Deep learning Workshop for Satellite Imagery - Data Processing\" tutorial found on YouTube by Dr. Avkash Chauhan. Please see their Github page (https://github.com/prodramp/DeepWorks/tree/main/DL-SatelliteImagery) for the tutorial, code, and info."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6afaf",
   "metadata": {},
   "source": [
    "It uses Dubai dataset with Segmentation images, downloaded from Kaggle (https://www.kaggle.com/datasets/humansintheloop/semantic-segmentation-of-aerial-imagery). Humans in the Loop are the owners of the data (https://humansintheloop.org/resources/datasets/semantic-segmentation-dataset-2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e44b4111",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'patchify'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpatchify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m patchify\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'patchify'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from patchify import patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fabcc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the root directory for this project\n",
    "dataset_root_folder = \"C:/Users/chanc/Documents/Remote_Sensing/MBRSC_Dubai_samples\"\n",
    "\n",
    "#Name your dataset\n",
    "dataset_name = \"SemanticSegmentationDataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efbd5787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/chanc/Documents/Remote_Sensing/MBRSC_Dubai_samples\n",
      "SemanticSegmentationDataset\n",
      "Tile 1\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 2\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 3\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 4\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 5\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 6\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 7\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n",
      "Tile 8\n",
      "images\n",
      "['image_part_001.jpg', 'image_part_002.jpg', 'image_part_003.jpg', 'image_part_004.jpg', 'image_part_005.jpg', 'image_part_006.jpg', 'image_part_007.jpg', 'image_part_008.jpg', 'image_part_009.jpg']\n",
      "masks\n"
     ]
    }
   ],
   "source": [
    "#OSwalk helps us select a folder and returns the paths of subdirectories and files\n",
    "for path, subdirs, files in os.walk(dataset_root_folder):\n",
    "    dir_name = path.split(os.path.sep)[-1]\n",
    "    print(dir_name)\n",
    "    if dir_name == 'images':\n",
    "        images = os.listdir(path)\n",
    "        print(images)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60dded1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n",
      "image_part_001.png\n",
      "image_part_002.png\n",
      "image_part_003.png\n",
      "image_part_004.png\n",
      "image_part_005.png\n",
      "image_part_006.png\n",
      "image_part_007.png\n",
      "image_part_008.png\n",
      "image_part_009.png\n"
     ]
    }
   ],
   "source": [
    "for path, subdirs, files in os.walk(dataset_root_folder):\n",
    "    dir_name = path.split(os.path.sep)[-1]\n",
    "    #print(dir_name)\n",
    "    if dir_name == 'masks': #images\n",
    "        images = os.listdir(path)\n",
    "        #print(images)\n",
    "        for i, image_name in enumerate(images):\n",
    "            print(image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65475e52",
   "metadata": {},
   "source": [
    "Can use the above code to specify the type of image to confirm image type (e.g. jpeg or png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba4ce697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[201, 195, 190],\n",
       "        [225, 219, 214],\n",
       "        [241, 232, 228],\n",
       "        ...,\n",
       "        [255, 236, 231],\n",
       "        [254, 234, 229],\n",
       "        [255, 239, 234]],\n",
       "\n",
       "       [[226, 220, 215],\n",
       "        [254, 248, 243],\n",
       "        [255, 255, 251],\n",
       "        ...,\n",
       "        [252, 231, 229],\n",
       "        [247, 228, 223],\n",
       "        [242, 223, 218]],\n",
       "\n",
       "       [[248, 241, 238],\n",
       "        [255, 252, 249],\n",
       "        [255, 255, 251],\n",
       "        ...,\n",
       "        [253, 234, 231],\n",
       "        [252, 235, 232],\n",
       "        [245, 228, 225]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[211, 200, 203],\n",
       "        [220, 209, 212],\n",
       "        [221, 211, 217],\n",
       "        ...,\n",
       "        [220, 229, 242],\n",
       "        [234, 243, 255],\n",
       "        [235, 244, 255]],\n",
       "\n",
       "       [[209, 198, 201],\n",
       "        [219, 208, 211],\n",
       "        [220, 210, 216],\n",
       "        ...,\n",
       "        [213, 222, 235],\n",
       "        [222, 231, 244],\n",
       "        [218, 227, 240]],\n",
       "\n",
       "       [[213, 202, 205],\n",
       "        [210, 199, 202],\n",
       "        [201, 191, 197],\n",
       "        ...,\n",
       "        [223, 232, 245],\n",
       "        [233, 242, 255],\n",
       "        [230, 239, 252]]], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use cv2 in opencv to read the data in the image\n",
    "image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile 1/images/image_part_001.jpg',1)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "162621da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 797, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives you the height, width, and color type (e.g. grayscale)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6375bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Can get the image type\n",
    "print(type(image)) #It's in a numpy.nd array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc433cc",
   "metadata": {},
   "source": [
    "However, not all our images are the same shape (they have different dimesnions). We need to make sure everything is the same shape before we can begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcac8b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 797, 3)\n",
      "(644, 797, 3)\n",
      "(644, 797, 3)\n",
      "(643, 797, 3)\n",
      "(643, 797, 3)\n",
      "(643, 797, 3)\n",
      "(644, 797, 3)\n",
      "(644, 797, 3)\n",
      "(644, 797, 3)\n",
      "(544, 509, 3)\n",
      "(544, 510, 3)\n",
      "(544, 509, 3)\n",
      "(544, 509, 3)\n",
      "(544, 510, 3)\n",
      "(544, 509, 3)\n",
      "(544, 509, 3)\n",
      "(544, 510, 3)\n",
      "(544, 509, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(658, 682, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(846, 1099, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(1058, 1126, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(838, 859, 3)\n",
      "(2061, 1817, 3)\n",
      "(2061, 1816, 3)\n",
      "(2061, 1817, 3)\n",
      "(2062, 1817, 3)\n",
      "(2062, 1816, 3)\n",
      "(2062, 1817, 3)\n",
      "(2061, 1817, 3)\n",
      "(2061, 1816, 3)\n",
      "(2061, 1817, 3)\n"
     ]
    }
   ],
   "source": [
    "image_dataset = [] #create an array since the imageset is divided into diff tiles. Iterate and create tile_id for each tile to make this easier\n",
    "image_extension = 'jpg' #since we want the jpg images right now\n",
    "for tile_id in range(1,8):\n",
    "    for image_id in range(1,20):\n",
    "        image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/images/image_part_00{image_id}.{image_extension}', 1)\n",
    "        if image is not None:\n",
    "            print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b33ea6",
   "metadata": {},
   "source": [
    "So we see each tile has different dimensions. You could do the same for the Masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7bada1",
   "metadata": {},
   "source": [
    "### Tile and Mask processing\n",
    "1. Decide the patch size for our images (i.e. 256x256 or 512x512)\n",
    "2. Make sure all the tiles and mask images size are multiples of the patch size\n",
    "3. Split all the images into the patch size and convert it into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fde888c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's define patch size\n",
    "image_patch_size = 256\n",
    "\n",
    "#Get image shape again, use Tile 2\n",
    "image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile 2/images/image_part_001.jpg',1)\n",
    "image.shape\n",
    "#If image size is 544x509, this doesn't match up with the 256, so we need to mod it with our patch size\n",
    "(image.shape[0]//image_patch_size)*image_patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1add59c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(644, 797, 3) --- 768 - 512\n",
      "(644, 797, 3) --- 768 - 512\n",
      "(644, 797, 3) --- 768 - 512\n",
      "(643, 797, 3) --- 768 - 512\n",
      "(643, 797, 3) --- 768 - 512\n",
      "(643, 797, 3) --- 768 - 512\n",
      "(644, 797, 3) --- 768 - 512\n",
      "(644, 797, 3) --- 768 - 512\n",
      "(644, 797, 3) --- 768 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(544, 510, 3) --- 256 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(544, 510, 3) --- 256 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(544, 510, 3) --- 256 - 512\n",
      "(544, 509, 3) --- 256 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(658, 682, 3) --- 512 - 512\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(846, 1099, 3) --- 1024 - 768\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(1058, 1126, 3) --- 1024 - 1024\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(838, 859, 3) --- 768 - 768\n",
      "(2061, 1817, 3) --- 1792 - 2048\n",
      "(2061, 1816, 3) --- 1792 - 2048\n",
      "(2061, 1817, 3) --- 1792 - 2048\n",
      "(2062, 1817, 3) --- 1792 - 2048\n",
      "(2062, 1816, 3) --- 1792 - 2048\n",
      "(2062, 1817, 3) --- 1792 - 2048\n",
      "(2061, 1817, 3) --- 1792 - 2048\n",
      "(2061, 1816, 3) --- 1792 - 2048\n",
      "(2061, 1817, 3) --- 1792 - 2048\n"
     ]
    }
   ],
   "source": [
    "#So let's go back and add in the patch size definition\n",
    "image_dataset = [] #create an array since the imageset is divided into diff tiles. Iterate and create tile_id for each tile to make this easier\n",
    "image_extension = 'jpg' #since we want the jpg images right now\n",
    "for tile_id in range(1,8):\n",
    "    for image_id in range(1,20):\n",
    "        image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/images/image_part_00{image_id}.{image_extension}', 1)\n",
    "        if image is not None:\n",
    "            #print(image.shape)\n",
    "            size_x = (image.shape[1]//image_patch_size)*image_patch_size #Recall, image shape is y first for height, then x second for width. Not cartesian default\n",
    "            size_y = (image.shape[0]//image_patch_size)*image_patch_size\n",
    "            #print(\"{} --- {} - {}\".format(image.shape, size_x, size_y))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88c4158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to convert image type from numpy.ndarray like we saw earlier to the image type\n",
    "type(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af1f0c",
   "metadata": {},
   "source": [
    "We've turned it from nd array to the image type. Now back to our image dataset code and crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4b550b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(768, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(256, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(512, 512)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 768)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(1024, 1024)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(768, 768)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n",
      "(1792, 2048)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_dataset = [] #create an array since the imageset is divided into diff tiles. Iterate and create tile_id for each tile to make this easier\n",
    "image_extension = 'jpg' #since we want the jpg images right now\n",
    "for tile_id in range(1,8):\n",
    "    for image_id in range(1,20):\n",
    "        image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/images/image_part_00{image_id}.{image_extension}', 1)\n",
    "        if image is not None:\n",
    "            #print(image.shape)\n",
    "            size_x = (image.shape[1]//image_patch_size)*image_patch_size #Recall, image shape is y first for height, then x second for width. Not cartesian default\n",
    "            size_y = (image.shape[0]//image_patch_size)*image_patch_size\n",
    "            #print(\"{} --- {} - {}\".format(image.shape, size_x, size_y))\n",
    "            image = Image.fromarray(image)\n",
    "            image = image.crop((0,0, size_x, size_y)) #crop image to our size\n",
    "            print(\"({}, {})\".format(image.size[0],image.size[1]))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f817b",
   "metadata": {},
   "source": [
    "Now the images are cropped and a multiple of the patch size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7d2f916c2605477a3263156fdcbac78ad2f047a19505b697f9f8ef44d8455de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
